<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Yuxuan Zhang - NUS</title>

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;700&display=swap" rel="stylesheet">

        <link rel="stylesheet" href="style.css">

        <style>
            button.active {
                font-weight: bold;
            }

            /* 1. ÂÆö‰πâ‰∏Ä‰∏™‚ÄúÊ∏êÂÖ•‚ÄùÁöÑÂä®Áîª */
            @keyframes fadeIn {
                from {
                    opacity: 0; /* ‰ªéÂÆåÂÖ®ÈÄèÊòéÂºÄÂßã */
                    transform: translateY(10px); /* È¢ùÂ§ñÔºö‰ªé‰∏ãÊñπ 10px ÁöÑ‰ΩçÁΩÆÂºÄÂßã */
                }
                to {
                    opacity: 1; /* Ê∏êÂèòÂà∞ÂÆåÂÖ®‰∏çÈÄèÊòé */
                    transform: translateY(0); /* È¢ùÂ§ñÔºöÁßªÂä®Âà∞ÂÖ∂ÂéüÂßã‰ΩçÁΩÆ */
                }
            }

            .content-page {
                display: none; 
                /* overflow: auto; */
            }

            .content-page.active {
                display: block; 
                animation: fadeIn 0.4s ease-out;
            }

            .gallery img {
                max-width: 95%;
                max-height: 150pt;
                margin-top: 15pt;
                margin-left: 15pt;

                border: solid 1px rgba(43, 34, 29, 0.3); 
                border-radius: 20pt;
                box-shadow: 0 0 3px 3px rgba(43, 34, 29, 0.3); 

                position: relative;
                opacity: 0;
                animation: fadeIn 0.5s ease-out forwards;
                transition: transform 0.3s ease, box-shadow 0.3s ease;
            }

            .gallery img:hover {
                transform: scale(1.05); 
                box-shadow: 0 4px 10px 5px rgba(43, 34, 29, 0.4); 

                z-index: 10;
            }

            #load-more-trigger {
                width: 100%;
                height: 50px; /* ‰∏Ä‰∏™‰∏çÂèØËßÅÁöÑËß¶ÂèëÂå∫Âüü */
            }
        </style>
    </head>

    <body>
        
        <div style="
            display: flex; 
            justify-content: center; 
            padding-top: 20px; 
            padding-bottom: 20px; 
            background-color: rgba(255, 255, 255, 0);
            
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            z-index: 10;">

            <div style="
                display: flex; 
                justify-content: center; 
                align-items: center; 
                width: fit-content;
                border: solid 1px rgb(43, 34, 29); 
                border-radius: 20px; 
                box-shadow: 0 0 5px 3px rgb(43, 34, 29); 
                padding: 1pt; 
                backdrop-filter: blur(10px);
                -webkit-backdrop-filter: blur(5px);">

                <button class="nav-button active" data-target="home">Homepage</button>
                <button class="nav-button" data-target="education">Education</button>
                <button class="nav-button" data-target="publications">Publications</button>
                <button class="nav-button" data-target="experience">Experience</button>
                <button class="nav-button" data-target="projects">Projects</button>
                <button class="nav-button" data-target="about">About</button>

            </div>

        </div>

        <div style="
            display: flex; 
            justify-content: center;">

            <div style="
                width: 60%; 
                margin-top: 50pt;
                justify-content: center;">

                <div id="home" class="content-page active">
                    <h2>Welcome ü§ó</h2>
                    <p>Hi, this is Yuxuan Zhang from China üá®üá≥. </p>
                    <p>
                        I am currently pursuing my Master's degree at the <a href="https://nus.edu.sg">National University of Singapore</a>. 
                        I completed my undergraduate studies at the <a href="http://en.hit.edu.cn">Harbin Institute of Technology</a>.
                    </p>
                    <p>
                        My research interests focus on Robotics, Computer Vision and HCI. 
                        For more detailed information you can check my <button class="nav-button" data-target="publications" style="padding-left: 0; padding-right: 0;">publications</button>, <button class="nav-button" data-target="experience" style="padding-left: 0; padding-right: 0;">experience</button> and <button class="nav-button" data-target="projects" style="padding-left: 0; padding-right: 0;">projects</button>. 
                    </p>
                    <br>
                    <p>
                        Always looking for a PhD opportunity... ü•≤
                    </p>
                    <!-- <p>
                        I got work experience at AMD and A*STAR.
                    </p> -->
                </div>

                <div id="education" class="content-page">
                    <h2>Education üìñ</h2>
                    <ul>
                        <li>
                            <span style="font-weight: bold;">Master in Artificial Intelligence Systems</span> <br>
                            National University of Singapore <br>
                            Aug, 2025 - Aug, 2026
                            <ul>
                                <li>GPA: TBD</li>
                                <li>Courses: Machine Reasoning Systems, Pattern Recognition Systems, Intelligent Robotics Systems, Intelligent Sensing Systems, Practical Language Processing</li>
                            </ul>
                            <button class="skill">Neural Network</button>
                            <button class="skill">Decision Tree</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Graduate Diploma in System Analysis</span> <br>
                            National University of Singapore <br>
                            Jul, 2023 - Jan, 2025
                            <ul>
                                <li>GPA: 4.11 / 5.0</li>
                                <li>Courses: Software Analysis & Design, Machine Learning, Web Application Development, Mobile Application Development</li>
                            </ul>
                            <button class="skill">Java</button>
                            <button class="skill">SprintBoot</button>
                            <button class="skill">AndroidSDK</button>
                            <button class="skill">C#</button>
                            <button class="skill">ASP.NET</button>
                            <button class="skill">Python</button>
                            <button class="skill">Machine Learning</button>
                            <button class="skill">Scikit-learn</button>
                            <button class="skill">TensorFlow</button>
                            <button class="skill">Keras</button>
                            <button class="skill">Numpy</button>
                            <button class="skill">Pandas</button>
                            <button class="skill">Matplotlib</button>
                            <button class="skill">Figma</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Bachelor in Intelligent Test and Control Engineering</span> <br>
                            Harbin Institute of Technology <br>
                            Sept, 2020 - Jun, 2024
                            <ul>
                                <li>GPA: 4.02 / 5.0</li>
                                <li>Courses: Intelligent Measurement & Control Systems, Distributed Test & Control Systems, Intelligent Sensing, Embedded Systems, Artificial Intelligence, Pattern Recognition & Machine Learning, FPGA Digital Systems, Digital Signal Processing, Microwave Technology</li>
                            </ul>
                            <button class="skill">MATLAB</button>
                            <button class="skill">DSP</button>
                            <button class="skill">LabVIEW</button>
                            <button class="skill">Automation</button>
                            <button class="skill">Altium Designer</button>
                            <button class="skill">AutoCAD</button>
                            <button class="skill">FPGA</button>
                            <button class="skill">Xilinx Vivado</button>
                            <button class="skill">Python</button>
                            <button class="skill">C</button>
                            <button class="skill">RS-232</button>
                            <button class="skill">PXI</button>
                            <button class="skill">LAN</button>
                        </li>
                    </ul>
                </div>

                <div id="publications" class="content-page">
                    <h2>Publications üìë</h2>
                    <ul>
                        <li>
                            <!-- <a href="">Learning to Synthesize Novel Human-Object Interaction in Collaborative Task-Based Settings</a> <br> -->
                            <span style="font-weight: bold;">Learning to Synthesize Novel Human-Object Interaction in Collaborative Task-Based Settings</span> <br>
                            AAAI 2026 Workshop HCM Submission <br>
                            Author: Haziq Razali, <span style="font-weight: bold;">Yuxuan Zhang</span>, Qianli Xu, Yiannis Demiris
                            <ul>
                                <li>Proposed a novel framework to address the lack of collaborative (multi-human) interaction datasets, integrating multi-view RGBD data collection with LLM-based reasoning. </li>
                                <li>Designed a data capture setup using wide-view and close-up RGBD cameras for markerless 3D reconstruction of human and object motion. </li>
                                <li>Utilized SOTA models for tracking, including 4D-Humans (body), HaMeR (hands), and SAM-6D (object), to generate temporally aligned 3D meshes from RGBD streams. </li>
                                <li>Employed Large Language Models (LLMs) to infer collaborative intent, parse complex tasks (e.g., "set the table") into semantic subtasks, and allocate roles to participants. </li>
                                <li>Used the LLM-generated task decomposition to guide a generative model, enabling the synthesis of long-horizon, collaborative human-object interaction sequences. </li>
                            </ul>

                            <button class="skill">HOI</button>
                            <button class="skill">Motion Synthesis</button>
                            <button class="skill">Task Decomposition</button>
                            <button class="skill">LLMs</button>
                            <button class="skill">Multi-View RGBD</button>
                            <button class="skill">3D Reconstruction</button>

                            <img src="imgs/hu.png" loading="lazy" alt="Learning to Synthesize Novel Human-Object Interaction in Collaborative Task-Based Settings">
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;"><a href="https://arxiv.org/abs/2506.17561">VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models</a></span> <br>
                            NeurIPS 2025 Workshop EWM Oral <br>
                            Author: Chongkai Gao, Zixuan Liu, Zhenghao Chi, Junshan Huang, Xin Fei, Yiwen Hou, <span style="font-weight: bold;">Yuxuan Zhang</span>, Yudi Lin, Zhirui Fang, Lin Shao
                            <ul>
                                <li>Proposed VLA-OS, a unified architecture suite, to systematically dissect and compare different planning paradigms and representations in VLA models. </li>
                                <li>Analyzed and benchmarked three mainstream VLA paradigms: ActionOnly-VLA, Integrated-VLA, and Hierarchical-VLA. </li>
                                <li>Designed and evaluated three distinct task planning representations: Language Reasoning, Visual Reasoning (e.g., bounding boxes, affordance), and Image Foresight (goal images). </li>
                                <li>Demonstrated experimentally that the Hierarchical-VLA paradigm generally achieves superior performance and that visually grounded planning representations outperform language-based representations. </li>
                            </ul>

                            <button class="skill">VLA</button>
                            <button class="skill">Task Planning Paradigms</button>
                            <button class="skill">Planning Representations</button>
                            <button class="skill">Hierarchical-VLA</button>
                            <button class="skill">VLA-OS</button>
                            <button class="skill">Robot Manipulation</button>

                            <img src="imgs/vla-os.png" loading="lazy" alt="VLA-OS">
                        </li>
                    </ul>
                </div>

                <div id="experience" class="content-page">
                    <h2>Experience üíº</h2>
                    <ul>
                        <li>
                            <span style="font-weight: bold;">Research Intern (Hardware / Software / System Design)</span> <br>
                            Advanced Micro Devices (Singapore) Pte Ltd <br>
                            Mar, 2026 - Aug, 2026
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Humanoid Robotics Development Intern</span> <br>
                            FatFish Technology Pte Ltd <br>
                            Oct, 2025 - Dec, 2025
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Research Intern</span> <br>
                            AdaComp Lab, National University of Singapore <br>
                            Jun, 2025 - Sept, 2025
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Research Intern</span> <br>
                            I2R, Agency for Science, Technology and Research (A*STAR)
                            Mar, 2025 - Dec, 2025
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Research & Development Intern</span> <br>
                            Changjiang Intelligent Technology Pte Ltd <br>
                            Jul, 2021 - Aug, 2021
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Game VFX Design Intern</span> <br>
                            Boke Network Technology (Hubei) Co Ltd <br>
                            Jan, 2021 - Feb, 2021
                        </li>
                    </ul>
                </div>

                <div id="projects" class="content-page">
                    <h2>Projects üíª</h2>
                    <ul>
                        <li>
                            <span style="font-weight: bold;">Motion Analysis in Gym</span> <br>
                            Sept, 2025 - Oct, 2025 <br>
                            <ul>
                                <li>Used 4D-Humans for human body tracking, HAMER for human hand tracking. Integrated SMPL model and MANO model into SMPLX model. </li>
                                <li>Trained a GRU (LSTM) model to classify different exercise types. </li>
                                <li>Trained AutoEncoders to correct human's motion in the certain exercise. </li>
                            </ul>

                            <button class="skill">Motion Tracking</button>
                            <button class="skill">LSTM</button>
                            <button class="skill">GRU</button>
                            <button class="skill">AutoEncoder</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">AI-Powered Scheduling System</span> <br>
                            Sept, 2025 - Oct, 2025 <br>
                            <ul>
                                <li>Used Evolution Algorithm to train task evaluation model (task attributes as input, predicted energy and pressure as output). </li>
                                <li>Developed a rule-based (deadline first, priority second) Scheduler to assign the flexible tasks. </li>
                                <li>Used MongoDB for database, FastAPI for backend, React.js for frontend. </li>
                            </ul>

                            <button class="skill">Evolution Algorithm</button>
                            <button class="skill">Rule-based Scheduler</button>
                            <button class="skill">Full-stack Development</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Deploying Gaussian Splatting on Apple Metal Chip</span> <br>
                            Sept, 2024 - Jan, 2025 <br>
                            <ul>
                                <li>Used OpenCV to calibrate the iPhone's camera. </li>
                                <li>Used RealityKit to pre-generate the scene model as the warmup of Gaussian Splatting, and to generate camera poses instead of COLMAP. </li>
                                <li>Optimized Gaussian Splatting workflow on Apple's M2 Chip, by transfer C++ to Swift and PyTorch to Metal. </li>
                                <li>Used Swift for UI. </li>
                            </ul>

                            <button class="skill">Gaussian Splatting</button>
                            <button class="skill">3D Reconstruction</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">CamC: Multi-Platform Camera Price Comparison & Prediction</span> <br>
                            Jun, 2024 - Aug, 2024 <br>
                            <ul>
                                <li>Trained a kNN model for camera classification, trained SVM models for camera price prediction. </li>
                                <li>Used MySQL for database, SprintBoot for backend, React.js for web frontend, AndroidSDK for mobile frontend. </li>
                            </ul>

                            <button class="skill">kNN</button>
                            <button class="skill">SVM</button>
                            <button class="skill">Full-stack Development</button> <br>

                            <img src="imgs/camc.png" loading="lazy" alt="CamC: Multi-Platform Camera Price Comparison & Prediction">
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Automated Calibration System for A/D Modules</span> <br>
                            Oct, 2023 - May, 2024 <br>
                            <ul>
                                <li>Designed a 16-channel selection circuit, designed the PCB board, soldered the circuit board. </li> 
                                <li>Developed embedded C firmware to enable RS-232 communication and implement channel selection functionality on the circuit board. </li>
                                <li>Enabled RS-232 communication to control the selection circuit and calibration source, enabled PXIe communication to read the output of the AD product. </li>
                                <li>Developed LabVIEW automation to control channel selection, control standard voltage outputs, read AD outputs, and perform AD calibration. </li>
                            </ul>
                            <button class="skill">Automation</button>
                            <button class="skill">Embedded Systems</button>
                            <button class="skill">Distributed Systems</button>
                            <button class="skill">Virtual Instruments</button> <br>

                            <img src="imgs/ad.png" loading="lazy" alt="Automated Calibration System for A/D Modules">
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Automated Signal Conditioning Circuit Testing System</span> <br>
                            Sept 2023 <br>
                            <ul>
                                <li>Enabled LAN communication to control instruments for synchronized measurement. </li>
                                <li>Developed LabVIEW automation. </li>
                            </ul>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">Automated Drone Docking & Charging Platform</span> <br>
                            Oct, 2021 - Sept, 2022 <br>
                            <ul>
                                <li><span style="font-weight: bold;">Provincial-Level College Students' Innovative Entrepreneurial Training Program</span></li>
                                <li>Used DJI Matrice 100 aircraft, Manifold 2-C flight control, and OpenMV camera. </li>
                                <li>Used GPS for general location (&gt;5m), tracked AprilTag for precise location (&lt;5m). </li>
                                <li>Used DJI OnboardSDK to develope automated landing algorithms. </li>
                            </ul>
                            
                            <button class="skill">Flight Control</button>
                            <button class="skill">Tag Tracking</button>
                            <button class="skill">Automation</button>
                        </li>
                        <hr>
                        <li>
                            <span style="font-weight: bold;">3D Port Reconstruction - Tianjin Port</span> <br>
                            Oct, 2020 - Sept, 2021 <br>
                            <ul>
                                <li>In Unity, imported the satellite elevation map as 3D model, the satellite orthophoto as texture, to construct a 3D scene. Imported interactive objects. </li>
                                <li>Developed C# scripts to control user perspective, enable object interactions, and simulate dynamic weather effects. </li>
                                <li>Packaged and deployed the complete simulation as an immersive application for VR devices. </li>
                            </ul>

                            <button class="skill">Unity</button>
                            <button class="skill">3D Reconstruction</button>
                            <button class="skill">C#</button>
                            <button class="skill">VR</button>
                        </li>
                    </ul>
                </div>

                <div id="about" class="content-page">
                    <h2>About Me üòé</h2>
                    <p>To contact me...</p>
                    <ul>
                        <li>
                            Website: 
                            <ul>
                                <li>LinkedIn: <a href="https://www.linkedin.com/in/yuxuanzhang271">www.linkedin.com/in/yuxuanzhang271</a></li>
                                <li>GitHub: <a href="https://github.com/YuxuanZhang271">github.com/YuxuanZhang271</a></li>
                            </ul>
                        </li>
                        <hr>
                        <li>
                            Email: 
                            <ul>
                                <li>School: <a href="mailto:e1216649@u.nus.edu">e1216649@u.nus.edu</a></li>
                                <li>Personal: <a href="mailto:942326836zyx@gmail.com">942326836zyx@gmail.com</a></li>
                            </ul>
                        </li>
                        <hr>
                        <li>
                            Address: #01-15, 28 West Coast Road, Singapore 127449
                            <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3988.7997078174403!2d103.76500747560303!3d1.294716898692994!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x31da1afb8e2fc2a1%3A0xcb9b0bde9afe88fe!2s28%20W%20Coast%20Rd%2C%20Singapore%20127449!5e0!3m2!1sen!2ssg!4v1762914406621!5m2!1sen!2ssg" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
                        </li>
                    </ul>
                    <hr>
                    <h2>Gallery</h2>
                    <div class="gallery"></div>
                    <div id="load-more-trigger"></div>
                </div>
            
            </div>

        </div>

        <script>
            document.addEventListener('DOMContentLoaded', () => {

                const buttons = document.querySelectorAll('.nav-button');
                const pages = document.querySelectorAll('.content-page');

                let isGalleryInitialized = false;
                const galleryContainer = document.querySelector('.gallery');
                const observerTarget = document.getElementById('load-more-trigger');
                let observer;
                const allImageFiles = [
                    '000039640003.jpeg', 
                    '000039640004.jpeg', 
                    '000039640007.jpeg',
                    '000039640014.jpeg', 
                    '000039640021.jpeg', 
                    '000039640030.jpeg',
                    '000039640031.jpeg',
                    '000039640032.jpeg',
                ];
                let shuffledImages = [];
                let currentIndex = 0;
                const batchSize = 10;

                function shuffleArray(array) {
                    let m = array.length, t, i;
                    while (m) {
                        i = Math.floor(Math.random() * m--);
                        t = array[m];
                        array[m] = array[i];
                        array[i] = t;
                    }
                    return array;
                }

                function loadNextBatch() {
                    const batch = shuffledImages.slice(currentIndex, currentIndex + batchSize);
                    
                    if (batch.length === 0) {
                        if (observer) observer.disconnect();
                        if (observerTarget) observerTarget.style.display = 'none';
                        return;
                    }

                    batch.forEach(fileName => {
                        const img = document.createElement('img');
                        img.src = 'imgs/gallery/' + fileName;
                        img.alt = 'Gallery image';
                        img.loading = 'lazy';
                        
                        galleryContainer.appendChild(img);
                    });

                    currentIndex += batchSize;
                }

                function initGallery() {
                    if (isGalleryInitialized) return;
                    isGalleryInitialized = true;
                    
                    galleryContainer.innerHTML = ''; 
                    shuffledImages = shuffleArray([...allImageFiles]);
                    currentIndex = 0;

                    const options = {
                        root: null,
                        rootMargin: '0px',
                        threshold: 0.1
                    };

                    observer = new IntersectionObserver((entries) => {
                        if (entries[0].isIntersecting) {
                            loadNextBatch();
                        }
                    }, options);

                    if (observerTarget) {
                        observer.observe(observerTarget);
                    } else {
                        loadNextBatch();
                    }
                }

                buttons.forEach(button => {
                    button.addEventListener('click', () => {
                        
                        const targetId = button.dataset.target;
                        
                        buttons.forEach(btn => btn.classList.remove('active'));
                        pages.forEach(page => page.classList.remove('active'));

                        buttons.forEach(btn => {
                            if (btn.dataset.target === targetId) {
                                btn.classList.add('active');
                            }
                        });
                        
                        const targetPage = document.getElementById(targetId);
                        if (targetPage) {
                            targetPage.classList.add('active');
                        }

                        if (targetId === 'about') {
                            initGallery();
                        }
                    });
                });

                const initialActivePage = document.querySelector('.content-page.active');
                if (initialActivePage && initialActivePage.id === 'about') {
                    initGallery();
                }
            });
        </script>
    </body>
</html>